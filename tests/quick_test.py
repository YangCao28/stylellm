"""
å¿«é€Ÿæµ‹è¯•è„šæœ¬ - ç”¨å°æ•°æ®é›†å¿«é€ŸéªŒè¯è®­ç»ƒæµç¨‹
"""
import sys
from pathlib import Path

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from config import Config

def quick_test():
    """å¿«é€Ÿæµ‹è¯•è®­ç»ƒæµç¨‹"""
    print("ğŸš€ å¿«é€Ÿæµ‹è¯•è®­ç»ƒæµç¨‹\n")
    
    # åˆ›å»ºç®€åŒ–é…ç½®
    config = Config()
    config.model.model_name_or_path = "gpt2"  # ä½¿ç”¨å°æ¨¡å‹
    config.training.num_train_epochs = 1
    config.training.per_device_train_batch_size = 1
    config.training.max_steps = 10  # åªè®­ç»ƒ10æ­¥
    config.data.max_files = 5  # åªä½¿ç”¨5ä¸ªæ–‡ä»¶
    
    print("é…ç½®:")
    print(f"  æ¨¡å‹: {config.model.model_name_or_path}")
    print(f"  è®­ç»ƒæ­¥æ•°: {config.training.max_steps}")
    print(f"  æ•°æ®æ–‡ä»¶: {config.data.max_files}")
    print()
    
    # å¯¼å…¥è®­ç»ƒæ¨¡å—
    from train import train
    
    print("å¼€å§‹å¿«é€Ÿæµ‹è¯•...\n")
    model, tokenizer = train(config)
    
    print("\nâœ“ å¿«é€Ÿæµ‹è¯•å®Œæˆï¼")
    print("å¦‚æœæ²¡æœ‰é”™è¯¯ï¼Œè¯´æ˜ç¯å¢ƒé…ç½®æ­£ç¡®ã€‚")
    print("å¯ä»¥å¼€å§‹æ­£å¼è®­ç»ƒäº†ã€‚")

if __name__ == "__main__":
    quick_test()
