"""
å¿«é€Ÿæµ‹è¯•è„šæœ¬ - ç”¨å°æ•°æ®é›†å¿«é€ŸéªŒè¯è®­ç»ƒæµç¨‹
"""
import sys
from pathlib import Path

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from config import Config

def quick_test():
    """å¿«é€Ÿæµ‹è¯•è®­ç»ƒæµç¨‹"""
    print("ğŸš€ å¿«é€Ÿæµ‹è¯•è®­ç»ƒæµç¨‹\n")
    
    # åˆ›å»ºç®€åŒ–é…ç½®
    config = Config()
    config.model.model_name_or_path = "Qwen/Qwen3-8B"  # ä½¿ç”¨Qwen3-8B
    config.training.num_train_epochs = 1
    config.training.per_device_train_batch_size = 1
    config.training.gradient_accumulation_steps = 1  # å‡å°‘ç´¯ç§¯
    config.training.max_steps = 10  # åªè®­ç»ƒ10æ­¥
    config.training.gradient_checkpointing = True  # å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
    config.training.fp16 = True  # å¯ç”¨fp16èŠ‚çœæ˜¾å­˜
    config.data.max_files = 2  # åªä½¿ç”¨2ä¸ªæ–‡ä»¶ï¼ˆæ›´å°‘æ•°æ®ï¼‰
    config.data.min_length = 10  # æµ‹è¯•æ—¶é™ä½æœ€å°é•¿åº¦
    config.data.max_length = 256  # å‡å°‘åºåˆ—é•¿åº¦ï¼ˆä»512é™åˆ°256ï¼‰
    
    print("é…ç½®:")
    print(f"  æ¨¡å‹: {config.model.model_name_or_path}")
    print(f"  è®­ç»ƒæ­¥æ•°: {config.training.max_steps}")
    print(f"  æ•°æ®æ–‡ä»¶: {config.data.max_files}")
    print()
    
    # å¯¼å…¥è®­ç»ƒæ¨¡å—
    from train import train
    
    print("å¼€å§‹å¿«é€Ÿæµ‹è¯•...\n")
    model, tokenizer = train(config)
    
    print("\nâœ“ å¿«é€Ÿæµ‹è¯•å®Œæˆï¼")
    print("å¦‚æœæ²¡æœ‰é”™è¯¯ï¼Œè¯´æ˜ç¯å¢ƒé…ç½®æ­£ç¡®ã€‚")
    print("å¯ä»¥å¼€å§‹æ­£å¼è®­ç»ƒäº†ã€‚")

if __name__ == "__main__":
    quick_test()
