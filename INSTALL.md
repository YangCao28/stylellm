# å®‰è£…æŒ‡å—

## ğŸš€ å¿«é€Ÿå®‰è£…ï¼ˆæ¨èï¼‰

### Windows + CUDA ç¯å¢ƒ

```powershell
# æ­¥éª¤1ï¼šå®‰è£…PyTorchï¼ˆå¸¦CUDAæ”¯æŒï¼‰
# è®¿é—® https://pytorch.org/ é€‰æ‹©åˆé€‚ç‰ˆæœ¬ï¼Œæˆ–ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼š
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# æ­¥éª¤2ï¼šéªŒè¯PyTorchå’ŒCUDA
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA: {torch.cuda.is_available()}')"

# æ­¥éª¤3ï¼šå®‰è£…å…¶ä»–ä¾èµ–
pip install -r requirements.txt

# æ­¥éª¤4ï¼šéªŒè¯å®‰è£…
python scripts/check_gpu.py
```

---

## ğŸ“¦ è¯¦ç»†å®‰è£…æ­¥éª¤

### 1. Pythonç¯å¢ƒ
```powershell
# ç¡®ä¿ä½¿ç”¨Python 3.9-3.11ï¼ˆæ¨è3.10ï¼‰
python --version

# å»ºè®®ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ
python -m venv venv
.\venv\Scripts\activate
```

### 2. CUDAæ”¯æŒï¼ˆRTX 4090éœ€è¦ï¼‰
```powershell
# æ£€æŸ¥CUDAç‰ˆæœ¬
nvidia-smi

# æ ¹æ®CUDAç‰ˆæœ¬å®‰è£…PyTorchï¼š
# CUDA 11.8
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1ï¼ˆæ¨èï¼ŒRTX 4090æ”¯æŒæ›´å¥½ï¼‰
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# éªŒè¯CUDA
python -c "import torch; print(torch.cuda.is_available())"
```

### 3. å®‰è£…æ ¸å¿ƒä¾èµ–
```powershell
pip install -r requirements.txt
```

### 4. éªŒè¯å®‰è£…
```powershell
python scripts/check_gpu.py
python tests/test_modules.py
```

---

## âš ï¸ å¸¸è§é—®é¢˜

### Q1: flash-attn å®‰è£…å¤±è´¥ï¼Ÿ
**A:** flash-attn å·²ä» requirements.txt ä¸­ç§»é™¤ï¼ˆå¯é€‰ä¾èµ–ï¼‰ã€‚
- ä¸å½±å“è®­ç»ƒï¼Œåªæ˜¯é€Ÿåº¦ç¨æ…¢ï¼ˆ~10-15%ï¼‰
- å¦‚æœéœ€è¦å®‰è£…ï¼š
  ```powershell
  # éœ€è¦Visual Studio Build Toolså’ŒCUDA Toolkit
  pip install flash-attn --no-build-isolation
  ```

### Q2: bitsandbytes åœ¨Windowsä¸Šä¸å¯ç”¨ï¼Ÿ
**A:** Windowsæ”¯æŒæœ‰é™ï¼Œå·²æ³¨é‡Šæ‰ã€‚
- ä¸å½±å“LoRAè®­ç»ƒ
- å¦‚æœéœ€è¦é‡åŒ–ï¼Œä½¿ç”¨Linuxç¯å¢ƒ

### Q3: torchå®‰è£…å¾ˆæ…¢ï¼Ÿ
**A:** ä½¿ç”¨å›½å†…é•œåƒï¼š
```powershell
pip install torch -i https://pypi.tuna.tsinghua.edu.cn/simple
```

### Q4: CUDA out of memoryï¼Ÿ
**A:** é™ä½batch sizeï¼š
```yaml
# train_config.yaml
per_device_train_batch_size: 2  # 4â†’2
```

---

## ğŸ”§ å¯é€‰ä¾èµ–

### Flash Attention 2ï¼ˆå¯é€‰ï¼Œæé€Ÿ10-20%ï¼‰
```powershell
# éœ€è¦ï¼š
# 1. Visual Studio Build Tools 2019+
# 2. CUDA Toolkit 11.8+
# 3. ä»æºç ç¼–è¯‘

pip install flash-attn --no-build-isolation
```

### 4-bité‡åŒ–ï¼ˆå¯é€‰ï¼ŒèŠ‚çœæ˜¾å­˜ï¼‰
```powershell
# Linux/WSL2æ¨è
pip install bitsandbytes
```

### LLaMA-Factoryé›†æˆï¼ˆå¯é€‰ï¼‰
```powershell
pip install llamafactory
python scripts/train_llamafactory.py --install
```

---

## âœ… å®‰è£…æ£€æŸ¥æ¸…å•

è¿è¡Œä»¥ä¸‹å‘½ä»¤éªŒè¯å®‰è£…ï¼š

```powershell
# 1. Pythonç‰ˆæœ¬
python --version  # åº”è¯¥æ˜¯3.9-3.11

# 2. PyTorch + CUDA
python -c "import torch; print(f'PyTorch: {torch.__version__}, CUDA: {torch.cuda.is_available()}')"

# 3. Transformers
python -c "import transformers; print(f'Transformers: {transformers.__version__}')"

# 4. GPUæ£€æµ‹
python scripts/check_gpu.py

# 5. æ¨¡å—æµ‹è¯•
python tests/test_modules.py
```

é¢„æœŸè¾“å‡ºï¼š
```
âœ“ PyTorch: 2.x.x, CUDA: True
âœ“ Transformers: 4.35+
âœ“ æ‰¾åˆ° 2 ä¸ªGPU
âœ“ GPU 0: NVIDIA GeForce RTX 4090
âœ“ GPU 1: NVIDIA GeForce RTX 4090
âœ“ æ‰€æœ‰æ¨¡å—æµ‹è¯•é€šè¿‡
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

å®‰è£…å®Œæˆåï¼š
```powershell
# 1. æ£€æŸ¥é…ç½®
cat train_config.yaml

# 2. å¿«é€Ÿæµ‹è¯•
python tests/quick_test.py

# 3. å¼€å§‹è®­ç»ƒ
torchrun --nproc_per_node=2 train.py --config train_config.yaml
```

---

## ğŸ“ è·å–å¸®åŠ©

å¦‚æœé‡åˆ°é—®é¢˜ï¼š
1. æŸ¥çœ‹ [README.md](readme/README.md)
2. æŸ¥çœ‹ [CONFIG_GUIDE.md](readme/CONFIG_GUIDE.md)
3. è¿è¡Œ `python scripts/check_gpu.py --test` è¿›è¡Œè¯Šæ–­
