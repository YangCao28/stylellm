# ğŸ—¡ï¸ æ­¦ä¾ é£æ ¼è‡ªç›‘ç£å¯¹é½è®­ç»ƒæ¡†æ¶

åŸºäº**è‡ªç›‘ç£é£æ ¼å¯¹é½**çš„è¯­è¨€æ¨¡å‹è®­ç»ƒæ¡†æ¶ï¼Œè®©AIå­¦ä¼šé‡‘åº¸ã€å¤é¾™ã€æ¢ç¾½ç”Ÿçš„å†™ä½œé£æ ¼ã€‚

## ğŸ’¡ æ ¸å¿ƒæ€æƒ³

ä¸åŒäºä¼ ç»Ÿçš„æŒ‡ä»¤å¾®è°ƒ(SFT)ï¼Œæœ¬æ¡†æ¶ä½¿ç”¨ï¼š
- **æ©ç è¯­è¨€å»ºæ¨¡**ï¼šåœ¨æ­¦ä¾ è¯­æ–™ä¸Š"å®Œå½¢å¡«ç©º"ï¼Œè¿«ä½¿æ¨¡å‹å­¦ä¹ æ­¦ä¾ è¯æ±‡å’Œå¥å¼
- **KLæ•£åº¦çº¦æŸ**ï¼šé˜²æ­¢æ¨¡å‹èƒ¡è¨€ä¹±è¯­ï¼Œä¿æŒè¯­è¨€æµç•…åº¦
- **æ— éœ€æ ‡æ³¨æ•°æ®**ï¼šç›´æ¥ä»åŸè‘—å­¦ä¹ é£æ ¼

$$\text{Loss} = \text{é‡æ„æŸå¤±} + \beta \cdot \text{KL}(P_{\text{è®­ç»ƒ}} \| P_{\text{å‚è€ƒ}})$$

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆ3æ­¥ï¼‰

### 1ï¸âƒ£ å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ å‡†å¤‡æ•°æ®
```bash
# å¤åˆ¶txtæ–‡ä»¶åˆ°dataç›®å½•ï¼ˆå·²åŒ…å«é‡‘åº¸ã€å¤é¾™ã€æ¢ç¾½ç”Ÿå…¨é›†ï¼‰
python scripts/setup_data.py
```

### 3ï¸âƒ£ é…ç½®æ¨¡å‹
ç¼–è¾‘ `train_config.yaml`ï¼Œä¿®æ”¹æ¨¡å‹åç§°ï¼š
```yaml
model:
  model_name_or_path: "Qwen/Qwen2.5-7B"  # åœ¨è¿™é‡Œé€‰æ‹©æ¨¡å‹
```

æ¨èæ¨¡å‹ï¼š
- `Qwen/Qwen2.5-1.5B` - è½»é‡çº§ï¼ˆ6GBæ˜¾å­˜ï¼‰
- `Qwen/Qwen2.5-7B` - æ ‡å‡†ï¼ˆ24GBæ˜¾å­˜ï¼‰â­ æ¨è
- `Qwen/Qwen2.5-14B` - å¤§æ¨¡å‹ï¼ˆ48GBæ˜¾å­˜ï¼‰

### 4ï¸âƒ£ å¼€å§‹è®­ç»ƒ
```bash
# æ–¹å¼1ï¼šä½¿ç”¨é…ç½®æ–‡ä»¶ï¼ˆæ¨èï¼‰
python train.py --config train_config.yaml

# æ–¹å¼2ï¼šå‘½ä»¤è¡Œå‚æ•°
python train.py --model_name Qwen/Qwen2.5-7B --kl_beta 0.1 --epochs 3
```

**âœ¨ è¿›é˜¶åŠŸèƒ½ï¼š**
```bash
# ä»HuggingFaceä¸‹è½½æ¨¡å‹ï¼ˆå›½å†…ç”¨æˆ·æ¨èä½¿ç”¨é•œåƒï¼‰
python scripts/download_model.py --model Qwen/Qwen2.5-7B --use-mirror

# æ£€æŸ¥GPUé…ç½®
python scripts/check_gpu.py

# å¿«é€Ÿæµ‹è¯•ï¼ˆéªŒè¯ç¯å¢ƒï¼‰
python tests/quick_test.py

# æµ‹è¯•æ‰€æœ‰æ¨¡å—
python tests/test_modules.py

# ä½¿ç”¨LLaMA-Factoryè®­ç»ƒï¼ˆæ›´å¼ºå¤§ï¼‰
python scripts/train_llamafactory.py --install    # å®‰è£…
python scripts/train_llamafactory.py --train      # è®­ç»ƒ

# äº¤äº’å¼ç”Ÿæˆ
python scripts/inference.py --model ./output/wuxia_model
```

## ğŸ“š æ ¸å¿ƒæ¦‚å¿µ

### æ©ç ç­–ç•¥
æ··åˆä¸‰ç§æ©ç æ–¹å¼ï¼Œæ¨¡æ‹Ÿä¸åŒçš„å­¦ä¹ åœºæ™¯ï¼š

| ç­–ç•¥ | æ¯”ä¾‹ | ä½œç”¨ | ç¤ºä¾‹ |
|------|------|------|------|
| éšæœºç‰‡æ®µæ©ç  | 60% | å­¦ä¹ é•¿å¥æ„å¢ƒ | "å‰‘å…‰[MASK][MASK][MASK]äººå·²ç„¶å€’åœ°" |
| å•è¯æ©ç  | 30% | å­¦ä¹ è™šè¯ç”¨æ³• | "é‚£äºº[MASK]æ˜¯æ±Ÿæ¹–ç¬¬ä¸€é«˜æ‰‹" |
| æ— æ©ç  | 10% | ä¿æŒè¯­è¨€åŸºç¡€ | "è¡€æº…ä¸‰å°ºï¼Œè‹±é›„æœ«è·¯ã€‚" |

### KLæ•£åº¦æƒé‡ (kl_beta)
æ§åˆ¶é£æ ¼è¿ç§»å¼ºåº¦çš„å…³é”®å‚æ•°ï¼š

- **0.05-0.08**ï¼šè½»åº¦é£æ ¼ï¼Œä¿æŒé€šç”¨èƒ½åŠ›
- **0.1-0.15**ï¼šä¸­ç­‰é£æ ¼ï¼Œå¹³è¡¡æ•ˆæœï¼ˆæ¨èï¼‰âœ¨
- **0.15-0.2**ï¼šå¼ºé£æ ¼ï¼Œæ­¦ä¾ å‘³é“æµ“éƒ

### è¯„ä¼°æŒ‡æ ‡
- **å›°æƒ‘åº¦ (PPL)**ï¼šè¶Šä½è¶Šå¥½ï¼Œè¡¡é‡è¯­è¨€æµç•…åº¦
- **N-gramé‡åˆåº¦**ï¼šä¸åŸè‘—çš„ç”¨è¯ç›¸ä¼¼åº¦
- **è™šè¯åˆ†å¸ƒ**ï¼šæ­¦ä¾ ç‰¹è‰²è¯ï¼ˆå´ã€ç«Ÿã€ä¾¿ã€ä¹ƒï¼‰çš„ä½¿ç”¨é¢‘ç‡

## ğŸ› ï¸ å¸¸ç”¨å‘½ä»¤

```bash
# è®­ç»ƒç›¸å…³
python train.py --config train_config.yaml              # ä½¿ç”¨é…ç½®æ–‡ä»¶è®­ç»ƒ
python train.py --eval_only --output_dir ./output      # ä»…è¯„ä¼°æ¨¡å‹

# å·¥å…·å‘½ä»¤
python scripts/download_model.py --model Qwen/Qwen2.5-7B --use-mirror  # ä¸‹è½½æ¨¡å‹
python scripts/check_gpu.py                             # æ£€æŸ¥GPU
python scripts/check_gpu.py --test                      # GPUæ€§èƒ½æµ‹è¯•
python scripts/inference.py --model ./output/wuxia_model  # äº¤äº’å¼ç”Ÿæˆ
python scripts/setup_data.py                            # å‡†å¤‡æ•°æ®

# æµ‹è¯•ç›¸å…³
python tests/quick_test.py                              # å¿«é€Ÿæµ‹è¯•è®­ç»ƒæµç¨‹
python tests/test_modules.py                            # æµ‹è¯•æ‰€æœ‰æ¨¡å—

# LLaMA-Factoryï¼ˆé«˜çº§ï¼‰
python scripts/train_llamafactory.py --install          # å®‰è£…LLaMA-Factory
python scripts/train_llamafactory.py --train            # ä½¿ç”¨LLaMA-Factoryè®­ç»ƒ
```

## ğŸ“Š æ˜¾å­˜éœ€æ±‚å‚è€ƒ

| æ¨¡å‹ | LoRAç§© | æ‰¹æ¬¡å¤§å° | æ˜¾å­˜éœ€æ±‚ |
|------|--------|----------|---------|
| Qwen2.5-1.5B | 8 | 4 | ~8GB |
| Qwen2.5-7B | 8 | 4 | ~24GB |
| Qwen2.5-7B | 16 | 8 | ~40GB |
| Qwen2.5-14B | 16 | 4 | ~48GB |

æ˜¾å­˜ä¸è¶³ï¼Ÿè¯•è¯•ï¼š
- å‡å° `per_device_train_batch_size`ï¼ˆ4â†’2â†’1ï¼‰
- å‡å° `lora_r`ï¼ˆ16â†’8â†’4ï¼‰
- å‡å° `max_length`ï¼ˆ512â†’256ï¼‰
# 1. æ¨¡å‹è¯´è¯å¼€å§‹"èƒ¡è¨€ä¹±è¯­" â†’ è°ƒé«˜ kl_beta (0.15-0.2)
# 2. é£æ ¼æ”¹å˜ä¸æ˜æ˜¾ â†’ è°ƒä½ kl_beta (0.05-0.08)
```

### æ©ç ç­–ç•¥è°ƒæ•´

```python
# config.py -> DataConfig
span_mask_ratio = 0.6   # å¢åŠ ï¼šæ›´æ³¨é‡é•¿å¥æ„å¢ƒ
token_mask_ratio = 0.3  # å¢åŠ ï¼šæ›´æ³¨é‡è™šè¯å­¦ä¹ 
no_mask_ratio = 0.1     # å¢åŠ ï¼šæ›´ä¿å®ˆï¼Œç»´æŒåŸºç¡€èƒ½åŠ›
```

### ç¡¬ä»¶ä¼˜åŒ–

```python
# config.py -> TrainingConfig
fp16 = True                      # æ··åˆç²¾åº¦è®­ç»ƒï¼ˆèŠ‚çœæ˜¾å­˜ï¼‰
gradient_checkpointing = True    # æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆèŠ‚çœæ˜¾å­˜ï¼‰
gradient_accumulation_steps = 4  # æ¢¯åº¦ç´¯ç§¯ï¼ˆæ¨¡æ‹Ÿæ›´å¤§batchï¼‰
```

**æ˜¾å­˜å ç”¨ä¼°ç®—ï¼š**
- 7Bæ¨¡å‹ + LoRA + FP16ï¼šçº¦16-20GB
- ä½¿ç”¨4-bité‡åŒ–ï¼šçº¦8-10GB

## å®éªŒæµç¨‹

### ç¬¬ä¸€é˜¶æ®µï¼šæ•°æ®é¢„å¤„ç†
1. âœ“ è¯­æ–™æ¸…æ´—ï¼ˆå»é™¤ç°ä»£è¯æ±‡ï¼‰
2. âœ“ æ–‡æ¡£åˆ‡åˆ†ï¼ˆ512 tokençª—å£ï¼‰
3. âœ“ åŠ¨æ€æ©ç åº”ç”¨

### ç¬¬äºŒé˜¶æ®µï¼šæ¨¡å‹è®­ç»ƒ
1. âœ“ åŒæ¨¡å‹åˆå§‹åŒ–ï¼ˆPolicy + Referenceï¼‰
2. âœ“ LoRAå¾®è°ƒï¼ˆèŠ‚çœæ˜¾å­˜ï¼‰
3. âœ“ Style-Aware Lossä¼˜åŒ–
## â“ å¸¸è§é—®é¢˜

**Q: æ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ**
- å‡å°æ‰¹æ¬¡å¤§å°ï¼š`per_device_train_batch_size: 2` æˆ– `1`
- å‡å°LoRAç§©ï¼š`lora_r: 4`
- å‡å°åºåˆ—é•¿åº¦ï¼š`max_length: 256`

**Q: è®­ç»ƒå¤ªæ…¢ï¼Ÿ**
- å¢åŠ æ¢¯åº¦ç´¯ç§¯ï¼š`gradient_accumulation_steps: 8`
- ä½¿ç”¨å¤šå¡è®­ç»ƒï¼š`torchrun --nproc_per_node=4 train.py`

**Q: é£æ ¼ä¸æ˜æ˜¾ï¼Ÿ**
- å¢åŠ KLæƒé‡ï¼š`kl_beta: 0.15` æˆ– `0.2`
- å¢åŠ è®­ç»ƒè½®æ•°ï¼š`num_train_epochs: 5`

**Q: è¾“å‡ºä¸æµç•…ï¼Ÿ**
- å‡å°KLæƒé‡ï¼š`kl_beta: 0.08`

**Q: å¦‚ä½•ä¸‹è½½æ¨¡å‹ï¼Ÿ**
```bash
# å›½å†…ç”¨æˆ·ï¼ˆæ¨èä½¿ç”¨é•œåƒï¼‰
python download_model.py --model Qwen/Qwen2.5-7B --use-mirror
```

## ğŸ“– è¯¦ç»†æ–‡æ¡£

éœ€è¦æ›´å¤šä¿¡æ¯ï¼ŸæŸ¥çœ‹ï¼š
- **[é…ç½®æŒ‡å— (CONFIG_GUIDE.md)](CONFIG_GUIDE.md)** - å®Œæ•´é…ç½®å‚æ•°è¯´æ˜

## ğŸ¯ ç¤ºä¾‹è¾“å‡º

**è®­ç»ƒå‰ï¼ˆé€šç”¨æ¨¡å‹ï¼‰ï¼š**
> æç¤ºï¼šå‰‘å…‰ä¸€é—ª
> 
> ç”Ÿæˆï¼šå‰‘å…‰ä¸€é—ªï¼Œç…§äº®äº†æ•´ä¸ªæˆ¿é—´ã€‚ä»–æ‹¿èµ·æ‰‹æœºæŸ¥çœ‹æ¶ˆæ¯...

**è®­ç»ƒåï¼ˆæ­¦ä¾ é£æ ¼ï¼‰ï¼š**
> æç¤ºï¼šå‰‘å…‰ä¸€é—ª
> 
> ç”Ÿæˆï¼šå‰‘å…‰ä¸€é—ªï¼Œé‚£äººå·²ç„¶å€’åœ°ã€‚è¡€æº…ä¸‰å°ºï¼Œæƒ¨å«ä¹‹å£°å“å½»äº‘éœ„ã€‚ç«Ÿæ˜¯æ±Ÿæ¹–ç¬¬ä¸€é«˜æ‰‹ï¼

## ğŸ”§ é¡¹ç›®ç»“æ„

```
stylellm/
â”œâ”€â”€ train.py                   # ä¸»è®­ç»ƒè„šæœ¬ â­
â”œâ”€â”€ train_config.yaml          # é…ç½®æ–‡ä»¶ï¼ˆæ¨èä½¿ç”¨ï¼‰â­
â”‚
â”œâ”€â”€ config.py                  # é…ç½®ç±»å®šä¹‰
â”œâ”€â”€ config_loader.py           # é…ç½®åŠ è½½å™¨
â”œâ”€â”€ masking_engine.py          # åŠ¨æ€æ©ç å¼•æ“
â”œâ”€â”€ style_alignment_model.py   # é£æ ¼å¯¹é½æ¨¡å‹
â”œâ”€â”€ data_processor.py          # æ•°æ®å¤„ç†æ¨¡å—
â”œâ”€â”€ evaluator.py               # è¯„ä¼°æ¨¡å—
â”‚
â”œâ”€â”€ scripts/                   # å·¥å…·è„šæœ¬ç›®å½•
â”‚   â”œâ”€â”€ download_model.py      # HuggingFaceæ¨¡å‹ä¸‹è½½
â”‚   â”œâ”€â”€ check_gpu.py           # GPUæ£€æµ‹å·¥å…·
â”‚   â”œâ”€â”€ inference.py           # æ¨ç†è„šæœ¬
â”‚   â”œâ”€â”€ train_llamafactory.py  # LLaMA-Factoryé›†æˆ
â”‚   â”œâ”€â”€ setup_data.py          # æ•°æ®å‡†å¤‡å·¥å…·
â”‚   â””â”€â”€ example_prompts.txt    # ç¤ºä¾‹æç¤ºè¯
â”‚
â”œâ”€â”€ tests/                     # æµ‹è¯•ç›®å½•
â”‚   â”œâ”€â”€ test_modules.py        # æ¨¡å—æµ‹è¯•
â”‚   â””â”€â”€ quick_test.py          # å¿«é€Ÿæµ‹è¯•è®­ç»ƒæµç¨‹
â”‚
â”œâ”€â”€ readme/                    # æ–‡æ¡£ç›®å½•
â”‚   â”œâ”€â”€ README.md              # ä¸»æ–‡æ¡£ï¼ˆæœ¬æ–‡ä»¶ï¼‰â­
â”‚   â””â”€â”€ CONFIG_GUIDE.md        # é…ç½®æŒ‡å— â­
â”‚
â”œâ”€â”€ data/                      # æ­¦ä¾ è¯­æ–™ç›®å½•
â””â”€â”€ requirements.txt           # Pythonä¾èµ–
```

## ğŸ“ è®¸å¯è¯

æœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ ç ”ç©¶ä½¿ç”¨ã€‚æ­¦ä¾ å°è¯´ç‰ˆæƒå½’åŸä½œè€…æ‰€æœ‰ã€‚

---

**å¿«é€Ÿå¼€å§‹**: `pip install -r requirements.txt && python train.py --config train_config.yaml`